<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Technology on Chenism</title>
		<link>https://armandch.github.io/categories/technology/</link>
		<description>Recent content in Technology on Chenism</description>
		<generator>Hugo 0.55.5 -- gohugo.io</generator>
		<language>en</language>
		<managingEditor>armandch@gmail.com (I-Fan Chen)</managingEditor>
		<webMaster>armandch@gmail.com (I-Fan Chen)</webMaster>
		<copyright>I-Fan Chen â€” All rights reserved.</copyright>
		<lastBuildDate>Fri, 19 Apr 2019 01:14:50 -0400</lastBuildDate>
		<atom:link href="https://armandch.github.io/categories/technology/index.xml" rel="self" type="application/rss+xml" />
		<item>
			<title>Oracle unable to extend temp segment in tablespace</title>
			<link>https://armandch.github.io/posts/oracle-unable-to-extend-temp-segment-in-tablespace/</link>
			<pubDate>Fri, 19 Apr 2019 01:14:50 -0400</pubDate>
			<author>armandch@gmail.com (I-Fan Chen)</author>
			<guid isPermaLink="true">https://armandch.github.io/posts/oracle-unable-to-extend-temp-segment-in-tablespace/</guid>
			<description>&lt;p&gt;In order to test a data conversion tool which my team had been developing for weeks, we wanted to import the latest database dump from production to our develop environment so we can run the tool against the latest data and assess the conversion result.&lt;/p&gt;

&lt;p&gt;The database in our environment was Oracle 11g Release 2, and the DMP file to be imported was about 34 GB.  I let the import process ran overnight, only to realize next morning that it failed.  I checked the alert log which in our case is under &lt;code&gt;/ora01/app/oracle/diag/rdbms/orcl/orcldv/alert/log.xml&lt;/code&gt; and realized there was an error in the log: &lt;code&gt;ORA-1652: unable to extend temp segment by 1024 in tablespace&lt;/code&gt;.  At first this seemed weird to me but after talking to our DBA I realized this actually meant the datafile of the tablespace I was using, instead of system temp, reached its size limit.&lt;/p&gt;

&lt;p&gt;The reasonable solution to this problem was to add more datafile to my tablespace.  However I wanted to make sure the datafile really reached its limit.  So I ran the following query to find out the block size of my database:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v$parameter&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;where&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;db_block_size&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The result is 8,192.  According to a table I stole from StackOverflow, my maximum datafile size was 32 GB:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;Block Sz   Max Datafile Sz (Gb)   Max DB Sz (Tb)

--------   --------------------   --------------

   2,048                  8,192          524,264

   4,096                 16,384        1,048,528

   8,192                 32,768        2,097,056

  16,384                 65,536        4,194,112

  32,768                131,072        8,388,224&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And yes, the size of my datafile had indeed reached its limit.  So I proceeded to add one more datafile to my tablespace by running the following query:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;alter&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tablespace&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;my_tablespace&lt;/span&gt;
  &lt;span class=&#34;k&#34;&gt;add&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datafile&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;mytablespace02.dbf&amp;#39;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;size&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;autoextend&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;on&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;maxsize&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;unlimited&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And I can confirm the datafile was added by running the query below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bytes&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mb_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
       &lt;span class=&#34;n&#34;&gt;maxbytes&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;maxsize_set&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
       &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;dba_data_files&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After resume importing the dump file, everything worked like a charm.&lt;/p&gt;
</description>
		</item>
	</channel>
</rss>
